{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os, cv2, random, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### I.",
   "id": "bc650b9cf02d49f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_path = \"./dataset\"\n",
    "\n",
    "train_path = os.path.join(input_path, \"train\")\n",
    "val_path = os.path.join(input_path, \"val\")\n",
    "test_path = os.path.join(input_path, \"test\")\n",
    "\n",
    "data_dir = [dir for dir in sorted(os.listdir(input_path)) if os.path.isdir(os.path.join(input_path, dir))]\n",
    "label_names = [subdir for subdir in sorted(os.listdir(train_path)) if os.path.isdir(os.path.join(train_path, subdir))]"
   ],
   "id": "6ecfb1d63f8cdbbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "paths = [train_path, val_path, test_path]\n",
    "split_names = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "num_splits = len(paths)\n",
    "num_classes = len(label_names)\n",
    "\n",
    "fig, axes = plt.subplots(num_classes, num_splits, figsize=(15, 10))\n",
    "\n",
    "for i in range(num_splits):\n",
    "    for j in range(num_classes):\n",
    "        current_folder = os.path.join(paths[i], label_names[j])\n",
    "\n",
    "        all_images = [f for f in os.listdir(current_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "        if all_images:\n",
    "            img_name = random.choice(all_images)\n",
    "            img_path = os.path.join(current_folder, img_name)\n",
    "\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            ax = axes[j, i]; ax.imshow(img)\n",
    "            ax.set_title(f\"{split_names[i]}: {label_names[j]}\", fontsize=10); ax.axis('off')\n",
    "\n",
    "plt.show()"
   ],
   "id": "b3f145b8c67fbbaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### II.",
   "id": "4cca91a2395f7809"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(224, 224, interpolation=cv2.INTER_CUBIC),\n",
    "    A.GaussNoise(std_range=(0.012, 0.027), p=0.2),\n",
    "    A.ISONoise(color_shift=(0.15, 0.35), intensity=(0.1, 0.5), p=0.05),\n",
    "    A.ImageCompression(quality_range=(50, 100), p=0.25),\n",
    "    A.MotionBlur(blur_limit=3, p=0.2),\n",
    "    A.Affine(scale=(0.9, 1.1), translate_percent=(0.1, 0.1), rotate=(-15, 15), interpolation=cv2.INTER_CUBIC, border_mode=cv2.BORDER_REFLECT_101, p=0.5),\n",
    "    A.CoarseDropout(num_holes_range=(4, 8), hole_height_range=(4, 16), hole_width_range=(4, 16), fill=0, p=0.25),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.3),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_test_transforms = A.Compose([\n",
    "    A.Resize(224, 224, interpolation=cv2.INTER_CUBIC),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])"
   ],
   "id": "8e6e0564f3e6fb07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### III.",
   "id": "81e70ca3171f35e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def gen_df(img_dir, labels):\n",
    "    real_img_dir = os.path.join(img_dir, labels[0])\n",
    "    spoof_img_dir = os.path.join(img_dir, labels[1])\n",
    "\n",
    "    real_files = [os.path.join(real_img_dir, f) for f in os.listdir(real_img_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    spoof_files = [os.path.join(spoof_img_dir, f) for f in os.listdir(spoof_img_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    data = {\n",
    "        'file_path': real_files + spoof_files,\n",
    "        'label': [1] * len(real_files) + [0] * len(spoof_files)\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df_train = gen_df(train_path, label_names)\n",
    "df_val   = gen_df(val_path, label_names)\n",
    "df_test  = gen_df(test_path, label_names)"
   ],
   "id": "64a86e7528968a9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_train_0 = df_train[df_train['label']==0][:1223]\n",
    "df_train_1 = df_train[df_train['label']==1][:1223]\n",
    "df_train_balanced = pd.concat([df_train_0, df_train_1]).reset_index(drop=True)\n",
    "df_train_balanced = df_train_balanced.sample(frac=1, random_state=42).reset_index(drop=True)"
   ],
   "id": "4be56f069917be20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_val_0 = df_val[df_val['label']==0][:405]\n",
    "df_val_1 = df_val[df_val['label']==1][:405]\n",
    "df_val_balanced = pd.concat([df_val_0, df_val_1]).reset_index(drop=True)\n",
    "df_val_balanced = df_val_balanced.sample(frac=1, random_state=42).reset_index(drop=True)"
   ],
   "id": "40249357ab99befe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_test_0 = df_test[df_test['label']==0][:314]\n",
    "df_test_1 = df_test[df_test['label']==1][:314]\n",
    "df_test_balanced = pd.concat([df_test_0, df_test_1]).reset_index(drop=True)\n",
    "df_test_balanced = df_test_balanced.sample(frac=1, random_state=42).reset_index(drop=True)"
   ],
   "id": "1daeb018a7f8d048",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class FASDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['file_path']\n",
    "        label = self.df.iloc[idx]['label']\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = np.array(image)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            augmented = self.transforms(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.float32).unsqueeze(0)"
   ],
   "id": "6a192cb76c4fa16b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dataset = FASDataset(df_train_balanced, train_transforms)\n",
    "val_dataset = FASDataset(df_val_balanced, val_test_transforms)\n",
    "test_dataset = FASDataset(df_test_balanced, val_test_transforms)\n",
    "\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "dataloader_val = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ],
   "id": "a4ecf6f6a78b18cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### IV.",
   "id": "bc84a280e421374b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
    "\n",
    "class SpoofNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpoofNet, self).__init__()\n",
    "        weights = MobileNet_V2_Weights.DEFAULT\n",
    "        self.backbone = mobilenet_v2(weights=weights).features\n",
    "\n",
    "        self.custom_layers = nn.Sequential(\n",
    "            nn.Conv2d(1280, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.custom_layers(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SpoofNet().to(device)"
   ],
   "id": "8a420bf532e88c9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# import torch.optim as optim\n",
    "# from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "#\n",
    "# num_epochs = 30\n",
    "# learning_rate = 5e-5\n",
    "#\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# criterion = nn.BCELoss()\n",
    "# scheduler = ReduceLROnPlateau(\n",
    "#     optimizer, factor=0.2, patience=3, mode='min',\n",
    "#     threshold=0.005, min_lr=5e-7,\n",
    "# )\n",
    "#\n",
    "# history = {\n",
    "#     'train_loss': [], 'val_loss': [],\n",
    "#     'train_accuracy': [], 'val_accuracy': [],\n",
    "#     'learning_rate': [],\n",
    "# }\n",
    "#\n",
    "# best_val_loss = float('inf')\n",
    "# save_dir = './models'\n",
    "#\n",
    "# if not os.path.exists(save_dir):\n",
    "#     os.makedirs(save_dir)\n",
    "#\n",
    "# best_filepath = os.path.join(save_dir, \"mobilenetv2-best.pt\")\n",
    "#\n",
    "# def save_checkpoint(state, is_best):\n",
    "#     if is_best:\n",
    "#         torch.save(state, best_filepath)"
   ],
   "id": "bcfa49d9b0070698",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     train_metrics = {'loss': 0.0, 'correct': 0, 'total': 0}\n",
    "#\n",
    "#     pbar_train = tqdm(dataloader_train, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "#     for inputs, labels in pbar_train:\n",
    "#         inputs, labels = inputs.to(device), labels.to(device).float().view(-1, 1)\n",
    "#\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#\n",
    "#         train_metrics['loss'] += loss.item()\n",
    "#         preds = (outputs > 0.5).float()\n",
    "#         train_metrics['correct'] += (preds == labels).sum().item()\n",
    "#         train_metrics['total'] += labels.size(0)\n",
    "#\n",
    "#         pbar_train.set_postfix(acc=f\"{100 * train_metrics['correct'] / train_metrics['total']:.2f}%\")\n",
    "#\n",
    "#     model.eval()\n",
    "#     val_metrics = {'loss': 0.0, 'correct': 0, 'total': 0}\n",
    "#\n",
    "#     pbar_val = tqdm(dataloader_val, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\", leave=False)\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in pbar_val:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device).float().view(-1, 1)\n",
    "#             outputs = model(inputs)\n",
    "#\n",
    "#             val_metrics['loss'] += criterion(outputs, labels).item()\n",
    "#             val_metrics['correct'] += ((outputs > 0.5).float() == labels).sum().item()\n",
    "#             val_metrics['total'] += labels.size(0)\n",
    "#\n",
    "#     avg_train_loss = train_metrics['loss'] / len(dataloader_train)\n",
    "#     avg_val_loss = val_metrics['loss'] / len(dataloader_val)\n",
    "#     train_acc = 100 * train_metrics['correct'] / train_metrics['total']\n",
    "#     val_acc = 100 * val_metrics['correct'] / val_metrics['total']\n",
    "#     current_lr = optimizer.param_groups[0]['lr']\n",
    "#\n",
    "#     scheduler.step(avg_val_loss)\n",
    "#\n",
    "#     for k, v in zip(history.keys(), [avg_train_loss, avg_val_loss, train_acc, val_acc, current_lr]):\n",
    "#         history[k].append(v)\n",
    "#\n",
    "#     is_best = avg_val_loss < best_val_loss\n",
    "#     if is_best:\n",
    "#         best_val_loss = avg_val_loss\n",
    "#\n",
    "#         save_checkpoint({\n",
    "#             'epoch': epoch + 1,\n",
    "#             'state_dict': model.state_dict(),\n",
    "#             'optimizer': optimizer.state_dict(),\n",
    "#         }, is_best)\n",
    "#\n",
    "#     print(f\"\\nEpoch {epoch+1}: Train Loss {avg_train_loss:.4f}, Acc {train_acc:.2f}% | Val Loss {avg_val_loss:.4f}, Acc {val_acc:.2f}% | LR: {current_lr}\")\n",
    "#\n",
    "# history_path = os.path.join(save_dir, 'training_history.json')\n",
    "# with open(history_path, 'w') as f:\n",
    "#     json.dump(history, f)"
   ],
   "id": "6a673ce27f2ff3ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### V.",
   "id": "8d3387b2003f6b64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open('training_history.json', 'r') as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "ax1.plot(epochs, history['train_loss'], 'b-o', label='Train Loss', markersize=4)\n",
    "ax1.plot(epochs, history['val_loss'], 'r-s', label='Val Loss', markersize=4)\n",
    "ax1.set_title('Model Loss (Binary Cross Entropy)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(epochs, history['train_accuracy'], 'b-o', label='Train Accuracy', markersize=4)\n",
    "ax2.plot(epochs, history['val_accuracy'], 'r-s', label='Val Accuracy', markersize=4)\n",
    "ax2.set_title('Model Accuracy (%)', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_report.png', dpi=300); plt.show()"
   ],
   "id": "70829c847308d0f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pretrain_weight = 'mobilenetv2-best.pt'\n",
    "\n",
    "check_point = torch.load(pretrain_weight, map_location=torch.device('cpu'))\n",
    "\n",
    "model_dict = check_point['state_dict']\n",
    "epoch_ = check_point['epoch']\n",
    "\n",
    "model.load_state_dict(model_dict)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "criterion = nn.BCELoss()"
   ],
   "id": "aea2745b6b3b862b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "prog_bar_test = tqdm(dataloader_test, desc='Testing')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in prog_bar_test:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        predicted = (outputs > 0.5).int()\n",
    "\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "        prog_bar_test.set_postfix({\n",
    "            'accuracy': correct_predictions / total_predictions * 100,\n",
    "        })\n",
    "\n",
    "test_loss /= len(dataloader_test)\n",
    "accuracy = correct_predictions / total_predictions * 100\n",
    "\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')"
   ],
   "id": "29054b8935e7c036",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
